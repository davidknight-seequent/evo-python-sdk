{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Download a drilling campaign object and save it in CSV format\n",
    "\n",
    "This example shows how to download a drilling-campaign object from an Evo workspace and how to construct CSV files from the data.\n",
    "\n",
    "> **Note:** This notebook requires an existing drilling campaign object in your Evo workspace. \n",
    ">\n",
    "> If you don't have one yet, run the `create-a-drilling-campaign/sdk-examples.ipynb` notebook first to create a drilling campaign object that you can then download with this notebook.\n",
    "\n",
    "### Requirements\n",
    "\n",
    "You must have a Seequent account with the Evo entitlement to use this notebook.\n",
    "\n",
    "The following parameters must be provided:\n",
    "\n",
    "- The client ID of your Evo application.\n",
    "- The callback/redirect URL of your Evo application.\n",
    "\n",
    "To obtain these app credentials, refer to the [Apps and tokens guide](https://developer.seequent.com/docs/guides/getting-started/apps-and-tokens) in the Seequent Developer Portal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from evo.colormaps import ColormapAPIClient\n",
    "from evo.notebooks import FeedbackWidget, ServiceManagerWidget\n",
    "from evo.objects import ObjectAPIClient\n",
    "\n",
    "# Evo app credentials\n",
    "client_id = \"<your-client-id>\"  # Replace with your client ID\n",
    "redirect_url = \"<your-redirect-url>\"  # Replace with your redirect URL\n",
    "\n",
    "manager = await ServiceManagerWidget.with_auth_code(\n",
    "    redirect_url=redirect_url,\n",
    "    client_id=client_id,\n",
    ").login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Use the Evo Python SDK to create an object client and a data client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The object client will manage your auth token and Geoscience Object API requests.\n",
    "object_client = ObjectAPIClient(manager.get_environment(), manager.get_connector())\n",
    "\n",
    "# The colormap client will manage your colormap API requests.\n",
    "colormap_client = ColormapAPIClient(manager.get_environment(), manager.get_connector())\n",
    "\n",
    "# The data client will manage saving your data as Parquet and publishing your data to Evo storage.\n",
    "data_client = object_client.get_data_client(manager.cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Display all drilling campaigns in the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "all_objects = await object_client.list_all_objects()\n",
    "\n",
    "# Filter drilling campaigns\n",
    "drilling_campaigns = [obj for obj in all_objects if \"drilling-campaign\" in obj.schema_id.sub_classification]\n",
    "\n",
    "if len(drilling_campaigns) == 0:\n",
    "    print(\"No drilling campaigns found.\")\n",
    "else:\n",
    "    # Create dropdown options with name as label and ID as value\n",
    "    dropdown_options = [(obj.name.removesuffix(\".json\"), str(obj.id)) for obj in drilling_campaigns]\n",
    "\n",
    "    drilling_campaign_dropdown = widgets.Dropdown(\n",
    "        options=dropdown_options,\n",
    "        description=\"Drilling campaign:\",\n",
    "        disabled=False,\n",
    "        style={\"description_width\": \"initial\"},\n",
    "        layout=widgets.Layout(width=\"600px\"),\n",
    "    )\n",
    "\n",
    "    print(f\"Found {len(drilling_campaigns)} drilling campaign(s). Please select one:\")\n",
    "    display(drilling_campaign_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Select the drilling campaign object from the dropdown above. \n",
    "\n",
    "The cell below downloads the object metadata and prints the number of holes in the drilling campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from datetime import datetime\n",
    "from uuid import UUID\n",
    "\n",
    "from pygments import highlight\n",
    "from pygments.formatters import TerminalTrueColorFormatter\n",
    "from pygments.lexers import JsonLexer\n",
    "\n",
    "\n",
    "def serialize_for_display(obj):\n",
    "    \"\"\"Convert an object's attributes to a JSON-serializable dictionary.\"\"\"\n",
    "    if isinstance(obj, UUID):\n",
    "        return str(obj)\n",
    "    elif isinstance(obj, datetime):\n",
    "        return obj.isoformat()\n",
    "    elif isinstance(obj, list):\n",
    "        return [serialize_for_display(item) for item in obj]\n",
    "    elif isinstance(obj, dict):\n",
    "        return {key: serialize_for_display(value) for key, value in obj.items()}\n",
    "    elif hasattr(obj, \"__dict__\"):\n",
    "        return {key: serialize_for_display(value) for key, value in vars(obj).items()}\n",
    "    else:\n",
    "        return obj\n",
    "\n",
    "\n",
    "object_id = drilling_campaign_dropdown.value\n",
    "output_filename = \"drilling_campaign.xlsx\"\n",
    "\n",
    "downloaded_object = await object_client.download_object_by_id(object_id=object_id, version=None)\n",
    "\n",
    "metadata = downloaded_object.metadata\n",
    "downloaded_dict = downloaded_object.as_dict()\n",
    "\n",
    "print(\"\\nDrilling Campaign Structure:\\n\")\n",
    "serialized = serialize_for_display(downloaded_dict)\n",
    "print(highlight(json.dumps(serialized, indent=4), JsonLexer(), TerminalTrueColorFormatter(style=\"lightbulb\")))\n",
    "\n",
    "number_of_holes = downloaded_dict[\"hole_id\"][\"table\"][\"length\"]\n",
    "print(f\"\\nThe drilling campaign contains {number_of_holes} holes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "Download the drilling campaign and save as an Excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_table(table_info, fb=None):\n",
    "    if fb is None:\n",
    "        fb = FeedbackWidget(\"Downloading unknown table\")\n",
    "    return data_client.download_table(object_id=metadata.id, version_id=None, table_info=table_info, fb=fb)\n",
    "\n",
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Use the data client to download the coordinate data.\n",
    "hole_indices = (\n",
    "    await download_table(\n",
    "        downloaded_dict[\"hole_id\"][\"values\"],\n",
    "        fb=FeedbackWidget(f\"Downloading hole indices data as '{downloaded_dict['hole_id']['values']['data']}'\"),\n",
    "    )\n",
    ").to_pandas()\n",
    "index_to_name_map = (\n",
    "    await download_table(\n",
    "        downloaded_dict[\"hole_id\"][\"table\"],\n",
    "        fb=FeedbackWidget(\n",
    "            f\"Downloading hole index to name map data as '{downloaded_dict['hole_id']['table']['data']}'\"\n",
    "        ),\n",
    "    )\n",
    ").to_pandas()\n",
    "names = pd.DataFrame({\"key\": hole_indices[\"data\"]}).merge(index_to_name_map, on=\"key\", how=\"left\")[\"value\"]\n",
    "\n",
    "collar_locations = (\n",
    "    await download_table(\n",
    "        downloaded_dict[\"planned\"][\"collar\"][\"coordinates\"],\n",
    "        fb=FeedbackWidget(\n",
    "            f\"Downloading collar locations data as '{downloaded_dict['planned']['collar']['coordinates']['data']}'\"\n",
    "        ),\n",
    "    )\n",
    ").to_pandas()\n",
    "hole_lengths = (\n",
    "    await download_table(\n",
    "        downloaded_dict[\"planned\"][\"collar\"][\"distances\"],\n",
    "        fb=FeedbackWidget(\n",
    "            f\"Downloading collar hole distances table as '{downloaded_dict['planned']['collar']['distances']['data']}'\"\n",
    "        ),\n",
    "    )\n",
    ").to_pandas()\n",
    "chunk_data = (\n",
    "    await download_table(\n",
    "        downloaded_dict[\"planned\"][\"collar\"][\"holes\"],\n",
    "        fb=FeedbackWidget(\n",
    "            f\"Downloading collar chunks data as '{downloaded_dict['planned']['collar']['holes']['data']}'\"\n",
    "        ),\n",
    "    )\n",
    ").to_pandas()\n",
    "\n",
    "attributes = []\n",
    "# Use the data client to download the attribute data and merge it with the coordinates data.\n",
    "for attribute in downloaded_dict[\"planned\"][\"collar\"][\"attributes\"]:\n",
    "    attribute_name = attribute[\"name\"]\n",
    "    attribute_type = attribute[\"attribute_type\"]\n",
    "\n",
    "    # Download the attribute data. Every attribute has a 'values' data file.\n",
    "    values_data = (\n",
    "        await download_table(\n",
    "            table_info=attribute[\"values\"],\n",
    "            fb=FeedbackWidget(\n",
    "                f\"Downloading attribute '{attribute_name}' values data as '{attribute['values']['data']}'\"\n",
    "            ),\n",
    "        )\n",
    "    ).to_pandas()\n",
    "    attributes.append(values_data)\n",
    "\n",
    "df = pd.concat([names, collar_locations, hole_lengths, chunk_data, *attributes], axis=1)\n",
    "\n",
    "path_data = (\n",
    "    await download_table(\n",
    "        downloaded_dict[\"planned\"][\"path\"],\n",
    "        fb=FeedbackWidget(f\"Downloading collar path data as '{downloaded_dict['planned']['path']['data']}'\"),\n",
    "    )\n",
    ").to_pandas()\n",
    "\n",
    "processed_path_data = pd.concat(\n",
    "    [\n",
    "        path_data.iloc[start : start + length].reset_index(drop=True)\n",
    "        for start, length in zip(chunk_data[\"offset\"], chunk_data[\"count\"])\n",
    "    ],\n",
    "    axis=0,\n",
    ").reset_index(drop=True)\n",
    "hole_name = []\n",
    "\n",
    "for hole_id, count in zip(chunk_data[\"hole_index\"], chunk_data[\"count\"]):\n",
    "    hole_name.extend([index_to_name_map[index_to_name_map[\"key\"] == hole_id][\"value\"].values[0]] * count)\n",
    "processed_path_data[\"hole_name\"] = hole_name\n",
    "processed_path_data = processed_path_data[\n",
    "    [\"hole_name\"] + [col for col in processed_path_data.columns if col != \"hole_name\"]\n",
    "]\n",
    "\n",
    "attribute_tables = {}\n",
    "# Use the data client to download the attribute data and merge it with the coordinates data.\n",
    "if \"collections\" in downloaded_dict[\"planned\"]:\n",
    "    for attribute_table in downloaded_dict[\"planned\"][\"collections\"]:\n",
    "        collection_type = attribute_table[\"collection_type\"]\n",
    "        collection_name = f\"planned_{collection_type}_({attribute_table['name']})\"\n",
    "\n",
    "        if collection_type == \"interval\":\n",
    "            distance_container = attribute_table[\"from_to\"][\"intervals\"][\"start_and_end\"]\n",
    "            attribute_container = attribute_table[\"from_to\"][\"attributes\"]\n",
    "            distance_data = (\n",
    "                await data_client.download_table(\n",
    "                    object_id=metadata.id,\n",
    "                    version_id=None,\n",
    "                    table_info=distance_container,\n",
    "                    fb=FeedbackWidget(f\"Downloading distance data as '{distance_container['data']}'\"),\n",
    "                )\n",
    "            ).to_pandas()\n",
    "        elif collection_type == \"distance\":\n",
    "            distance_container = attribute_table[\"intervals\"][\"start_and_end\"]\n",
    "            attribute_container = attribute_table[\"distance\"][\"attributes\"]\n",
    "            distance_data = (\n",
    "                await data_client.download_table(\n",
    "                    object_id=metadata.id,\n",
    "                    version_id=None,\n",
    "                    table_info=distance_container,\n",
    "                    fb=FeedbackWidget(f\"Downloading distance data as '{distance_container['data']}'\"),\n",
    "                )\n",
    "            ).to_pandas()\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        attribute_chunk_data = (\n",
    "            await data_client.download_table(\n",
    "                object_id=metadata.id,\n",
    "                version_id=None,\n",
    "                table_info=attribute_table[\"holes\"],\n",
    "                fb=FeedbackWidget(f\"Downloading attribute chunk data as '{attribute_table['holes']['data']}'\"),\n",
    "            )\n",
    "        ).to_pandas()\n",
    "\n",
    "        columns = [distance_data]\n",
    "        for column in attribute_container:\n",
    "            attribute_name = column[\"name\"]\n",
    "            attribute_type = column[\"attribute_type\"]\n",
    "\n",
    "            column_data = (\n",
    "                await data_client.download_table(\n",
    "                    object_id=metadata.id,\n",
    "                    version_id=None,\n",
    "                    table_info=column[\"values\"],\n",
    "                    fb=FeedbackWidget(\n",
    "                        f\"Downloading attribute '{attribute_name}' column data as '{column['values']['data']}'\"\n",
    "                    ),\n",
    "                )\n",
    "            ).to_pandas()\n",
    "            column_data.columns = [\"data\"]\n",
    "\n",
    "            # If the attribute is a category, download the 'table' data as well.\n",
    "            if attribute_type == \"category\":\n",
    "                lookup_table = (\n",
    "                    await data_client.download_table(\n",
    "                        object_id=metadata.id,\n",
    "                        version_id=None,\n",
    "                        table_info=column[\"table\"],\n",
    "                        fb=FeedbackWidget(\n",
    "                            f\"Downloading attribute '{attribute_name}' lookup table data as '{column['table']['data']}'\"\n",
    "                        ),\n",
    "                    )\n",
    "                ).to_pandas()\n",
    "\n",
    "                # Merge the values data with the table data.\n",
    "                merged_data = pd.merge(column_data, lookup_table, left_on=\"data\", right_on=\"key\", how=\"left\")\n",
    "                # Drop the 'data' and 'key' columns from the merged data.\n",
    "                merged_data.drop(columns=[\"data\", \"key\"], inplace=True)\n",
    "                # Rename the 'value' column to the attribute name.\n",
    "                merged_data.rename(columns={\"value\": attribute_name}, inplace=True)\n",
    "                # Concatenate the merged data with the coordinates data.\n",
    "                columns.append(merged_data)\n",
    "\n",
    "            elif attribute_type == \"scalar\":\n",
    "                # Rename the 'data' column to the attribute name.\n",
    "                column_data.rename(columns={\"data\": attribute_name}, inplace=True)\n",
    "                # Concatenate the data with the coordinates data.\n",
    "                columns.append(column_data)\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown attribute type: {attribute_type}\")\n",
    "\n",
    "        attribute_tables[collection_name] = pd.concat(columns, axis=1)\n",
    "        attribute_tables[f\"{collection_name} (Cnk)\"] = attribute_chunk_data\n",
    "\n",
    "# Save the dataframe as a CSV file.\n",
    "with pd.ExcelWriter(output_filename) as writer:\n",
    "    df.to_excel(writer, sheet_name=\"Collars\", index=False)\n",
    "    path_data.to_excel(writer, sheet_name=\"Raw Paths\", index=False)\n",
    "    processed_path_data.to_excel(writer, sheet_name=\"Paths\", index=False)\n",
    "    for name, table in attribute_tables.items():\n",
    "        sheet_name = name[:31] if len(name) > 31 else name\n",
    "        table.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "print(f\"âœ“ Drilling campaign data successfully saved to '{output_filename}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evo-code-samples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
